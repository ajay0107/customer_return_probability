{
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  },
  "lastEditStatus": {
   "notebookId": "tmcw6l7bc5lxhqqevshi",
   "authorId": "2665515635921",
   "authorName": "AJAY01071992",
   "authorEmail": "ajay01071992@gmail.com",
   "sessionId": "086c3c8d-7e64-457c-a748-6969a9b150a4",
   "lastEditTime": 1749117102436
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "id": "c1d1dfba-dbe6-4584-a72f-1357b32d7374",
   "metadata": {
    "language": "python",
    "name": "PACKAGES_IMPORT"
   },
   "outputs": [],
   "source": "import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom snowflake.snowpark.context import get_active_session\nfrom snowflake.snowpark.types import FloatType, DateType\nfrom snowflake.snowpark import Session\nfrom snowflake.snowpark.functions import col, when, regexp_replace\nfrom datetime import datetime\nfrom snowflake.snowpark.functions import lit, current_date, current_timestamp\nfrom snowflake.snowpark.types import IntegerType\nfrom snowflake.ml.feature_store import (\n    FeatureStore,\n    FeatureView,\n    Entity,\n    CreationMode\n)\nfrom snowflake.ml.modeling.pipeline import Pipeline\nfrom snowflake.ml.modeling.xgboost import XGBClassifier\nfrom snowflake.ml.registry import Registry\nfrom snowflake.ml.model import model_signature\n# from snowflake.ml.modeling.model_selection import train_test_split",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9a22c5ca-ed47-4afe-be95-1342e919b086",
   "metadata": {
    "language": "python",
    "name": "HELPER_FUNCTIONS"
   },
   "outputs": [],
   "source": "def clean_column_names(df):\n    cleaned_cols = {col_name: col_name.strip().replace('\"', '') for col_name in df.columns}\n    return df.select([col(c).alias(cleaned_cols[c]) for c in df.columns])\n\ndef preprocess_before_feature_store(df):\n    # Clean column names\n    df = df.select([col(c).alias(c.strip().replace('\"', '')) for c in df.columns])\n\n    # Cast numeric fields properly\n    df = df.with_column(\"SeniorCitizen\", col(\"SeniorCitizen\").cast(IntegerType()))\n    df = df.with_column(\"tenure\", col(\"tenure\").cast(IntegerType()))\n    df = df.with_column(\"MonthlyCharges\", col(\"MonthlyCharges\").cast(\"float\"))\n    df = df.with_column(\n        \"TotalCharges\",\n        when(col(\"TotalCharges\") == ' ', None).otherwise(col(\"TotalCharges\")).cast(\"float\")\n    )\n\n    # Drop rows with nulls in critical numeric fields\n    df = df.filter(col(\"TotalCharges\").is_not_null())\n\n    return df\n\ndef preprocess_after_feature_store(df):\n    # Convert target to binary label\n    df = df.with_column(\"CHURN\", when(col(\"CHURN\") == \"Yes\", 1).otherwise(0))\n\n    # Categorical columns to one-hot encode\n    onehot_columns = [\n        \"GENDER\", \"PARTNER\", \"DEPENDENTS\", \"PHONESERVICE\", \"MULTIPLELINES\", \"INTERNETSERVICE\",\n        \"ONLINESECURITY\", \"ONLINEBACKUP\", \"DEVICEPROTECTION\", \"TECHSUPPORT\",\n        \"STREAMINGTV\", \"STREAMINGMOVIES\", \"CONTRACT\", \"PAPERLESSBILLING\", \"PAYMENTMETHOD\"\n    ]\n\n    # One-hot encoding manually\n    for column_name in onehot_columns:\n        unique_vals = df.select(col(column_name)).distinct().collect()\n        for row in unique_vals:\n            value = row[column_name]\n            if value is not None:\n                safe_value = str(value).replace(' ', '_').replace('-', '_').replace('(', '').replace(')', '')\n                new_col = f\"{column_name}_{safe_value}\"\n                df = df.with_column(new_col, when(col(column_name) == value, 1).otherwise(0))\n\n    # Drop original categorical columns\n    df = df.drop(*onehot_columns)\n    return df\n\ndef clean_total_charges_column(df):\n    \"\"\"\n    Cleans the TOTALCHARGES column:\n    - Replaces known invalid values ('', 'No', 'N/A', etc.) with NULL\n    - Removes non-numeric characters from valid entries\n    - Casts to FloatType\n    \"\"\"\n    df = df.with_column(\n        \"TOTALCHARGES_CLEANED\",\n        when(\n            (col(\"TOTALCHARGES\").is_null()) |\n            (col(\"TOTALCHARGES\") == '') |\n            (col(\"TOTALCHARGES\").isin(\"No\", \"N/A\", \"null\", \"None\")),\n            None\n        ).otherwise(\n            regexp_replace(col(\"TOTALCHARGES\"), r\"[^0-9.]\", \"\")\n        ).cast(FloatType())\n    )\n    # Optionally drop original and rename\n    df = df.drop(\"TOTALCHARGES\").with_column_renamed(\"TOTALCHARGES_CLEANED\", \"TOTALCHARGES\")\n    return df",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c695373e-ac74-4b62-a1f1-08206cbd5c81",
   "metadata": {
    "language": "python",
    "name": "SETUP_ENVIRONMENT"
   },
   "source": "session = get_active_session()\n\n# Add a query tag to the session. This helps with debugging and performance monitoring.\nsession.query_tag = session.query_tag = {\n    \"origin\": \"churn_data_science\",\n    \"name\": \"churn_prediction_model_training\",\n    \"version\": {\"major\": 1, \"minor\": 0},\n    \"attributes\": {\"training\": 1, \"source\": \"notebook\"}\n}\n\n# Set session context \nsession.use_role(\"DEV_DATA_SCIENCE\") \n# Set the compute warehouse (used to run queries and transformations)\nsession.use_warehouse(\"DEV_DATA_SCIENCE_WH\")\n\n# Set the active database (logical container for schemas and tables)\nsession.use_database(\"DEV_DATA_SCIENCE_DB\")\n\n# Set the active schema (namespace within the database)\nsession.use_schema(\"CHURN_MODEL_SCHEMA\")\n\n# Print the current role, warehouse, and database/schema\nprint(f\"Session role: {session.get_current_role()} \\nSession WH: {session.get_current_warehouse()} \\nSession DB.SCHEMA: {session.get_fully_qualified_current_schema()}\")\n\n# Feature Store schema reference\nFEATURE_STORE_SCHEMA = \"DEV_DATA_SCIENCE_DB.FEATURE_STORE_SCHEMA\"\n\n# Model Registry schema reference\nMODEL_REGISTRY_SCHEMA = \"DEV_DATA_SCIENCE_DB.MODEL_REGISTRY_SCHEMA\"\n\n# Print the current role, warehouse, and database/schema\nprint(f\"FEATURE_STORE_SCHEMA: {FEATURE_STORE_SCHEMA} \\nMODEL_REGISTRY_SCHEMA: {MODEL_REGISTRY_SCHEMA}\")\n",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "b0b8501c-51dd-4e0c-89e8-86e1b307cf90",
   "metadata": {
    "language": "python",
    "name": "cell5"
   },
   "outputs": [],
   "source": "# Read the SQL query string\nsql_file_path = \"TRAIN_CHURN_MODEL/features_ingest.sql\"\nwith open(sql_file_path, \"r\") as file:\n    sql_query = file.read()\n\n# Execute the SQL query using Snowpark\ndf = session.sql(sql_query)\n\n# Clean column names: remove quotes and standardize to uppercase\ncleaned_columns = {col_name: col_name.strip('\"').upper() for col_name in df.columns}\ndf = df.select([col(c).alias(cleaned_columns[c]) for c in df.columns])\n\n# Handle TOTALCHARGES: replace blank with NULL and cast to float\n# from snowflake.snowpark.functions import col, when, regexp_replace\n# from snowflake.snowpark.types import DoubleType\n\n# df = df.with_column(\n#     \"TOTALCHARGES\",\n#     when(\n#         # Handle NULLs and non-numeric garbage strings\n#         (col(\"TOTALCHARGES\").is_null()) |\n#         (col(\"TOTALCHARGES\") == '') |\n#         (col(\"TOTALCHARGES\").isin(\"No\", \"N/A\", \"null\", \"None\")),\n#         None\n#     ).otherwise(\n#         # Remove all characters except digits and dot, then cast\n#         regexp_replace(col(\"TOTALCHARGES\"), r\"[^0-9.]\", \"\").cast(DoubleType())\n#     )\n# )\n\n\n# Add SNAPSHOT_DATE column with current date\ndf = df.with_column(\"SNAPSHOT_DATE\", current_date())\n\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "86532cdd-f92b-41d9-9b91-1c25aa291b24",
   "metadata": {
    "language": "python",
    "name": "DATA_LOADING_AND_SAVE_IN_RAW_FEATURES_DATA"
   },
   "outputs": [],
   "source": "# Write to Snowflake table\ndf.write.mode(\"append\").save_as_table(\"RAW_FEATURES_DATA\")",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ed9613f5-ac01-4f09-a61a-2b5cf2509e1a",
   "metadata": {
    "language": "python",
    "name": "DATA_PREPROCESSING"
   },
   "outputs": [],
   "source": "df = clean_column_names(df)\ndf = preprocess_before_feature_store(df)\nlabel_df = df.select(col(\"CUSTOMERID\"), col(\"SNAPSHOT_DATE\"), col(\"CHURN\"))\ndf.show()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "98acd0ba-7657-4127-8b68-7c6f816adf4d",
   "metadata": {
    "language": "python",
    "name": "cell7"
   },
   "outputs": [],
   "source": "from snowflake.snowpark.functions import col, current_timestamp\nfrom snowflake.ml.feature_store import FeatureStore, CreationMode, FeatureView, Entity\nimport pandas as pd\nfrom datetime import datetime\n\n# Set session context\nsession.use_database(\"DEV_DATA_SCIENCE_DB\")\nsession.use_schema(\"FEATURE_STORE_SCHEMA\")\n\n# Initialize Feature Store\nfs = FeatureStore(\n    session=session,\n    database=\"DEV_DATA_SCIENCE_DB\",\n    name=\"FEATURE_STORE_SCHEMA\",\n    default_warehouse=session.get_current_warehouse(),\n    creation_mode=CreationMode.CREATE_IF_NOT_EXIST\n)\n\n# -----------------------------\n# Register Entity\nfrom snowflake.ml.feature_store import Entity\n\ncustomer_entity = Entity(\n    name=\"customer_entity\",\n    join_keys=[\"SNAPSHOT_DATE\", \"CUSTOMERID\"],\n    desc=\"Entity representing customer identifier\"\n)\nfs.register_entity(customer_entity)\n\n\n# -----------------------------\n# Track ingestion metadata manually\ndef log_feature_view_registration(name, version, desc, features):\n    metadata_df = pd.DataFrame([{\n        \"FEATURE_VIEW\": name,\n        \"VERSION\": version,\n        \"DESC\": desc,\n        \"FEATURES\": features,\n        \"INGESTED_AT\": datetime.now()\n    }])\n    session.write_pandas(metadata_df, \"FEATURE_VIEW_HISTORY\", mode=\"append\")\n\n# Make sure SNAPSHOT_DATE exists\ndf = df.with_column(\"SNAPSHOT_DATE\", current_timestamp())\n\n# -----------------------------\n# Demographic Features\ndemographic_features = FeatureView(\n    name=\"demographic_features\",\n    entities=[customer_entity],\n    feature_df=df.select(\n        col(\"SNAPSHOT_DATE\"),\n        col(\"CUSTOMERID\"),\n        col(\"GENDER\"),\n        col(\"SENIORCITIZEN\"),\n        col(\"PARTNER\"),\n        col(\"DEPENDENTS\")\n    ),\n    desc=\"Demographic-related features\"\n)\nfs.register_feature_view(demographic_features, version=\"1.0\")\nlog_feature_view_registration(\n    \"demographic_features\", \"1.0\", \"Demographic-related features\", demographic_features.feature_df.schema.names\n)\n\n# -----------------------------\n# Financial Features\nfinancial_features = FeatureView(\n    name=\"financial_features\",\n    entities=[customer_entity],\n    feature_df=df.select(\n        col(\"SNAPSHOT_DATE\"),\n        col(\"CUSTOMERID\"),\n        col(\"MONTHLYCHARGES\"),\n        col(\"TOTALCHARGES\"),\n        col(\"PAYMENTMETHOD\"),\n        col(\"PAPERLESSBILLING\")\n    ),\n    desc=\"Financial behavior and billing features\"\n)\nfs.register_feature_view(financial_features, version=\"1.0\")\nlog_feature_view_registration(\n    \"financial_features\", \"1.0\", \"Financial behavior and billing features\", financial_features.feature_df.schema.names\n)\n\n# -----------------------------\n# Usage Features\nusage_features = FeatureView(\n    name=\"usage_features\",\n    entities=[customer_entity],\n    feature_df=df.select(\n        col(\"SNAPSHOT_DATE\"),\n        col(\"CUSTOMERID\"),\n        col(\"PHONESERVICE\"),\n        col(\"MULTIPLELINES\"),\n        col(\"INTERNETSERVICE\"),\n        col(\"ONLINESECURITY\"),\n        col(\"ONLINEBACKUP\"),\n        col(\"DEVICEPROTECTION\"),\n        col(\"TECHSUPPORT\"),\n        col(\"STREAMINGTV\"),\n        col(\"STREAMINGMOVIES\"),\n        col(\"CONTRACT\")\n    ),\n    desc=\"Usage and service interaction features\"\n)\nfs.register_feature_view(usage_features, version=\"1.0\")\nlog_feature_view_registration(\n    \"usage_features\", \"1.0\", \"Usage and service interaction features\", usage_features.feature_df.schema.names\n)\n\n# -----------------------------\n# Spine Definition\nspine_df = df.select(col(\"CUSTOMERID\"), col(\"SNAPSHOT_DATE\"))\n\n# Retrieve views for joining\ndemographic_fv = fs.get_feature_view(name=\"demographic_features\", version=\"1.0\")\nfinancial_fv = fs.get_feature_view(name=\"financial_features\", version=\"1.0\")\nusage_fv = fs.get_feature_view(name=\"usage_features\", version=\"1.0\")\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "92c3ba14-f54e-4b3a-9cad-cd0a9b099fc2",
   "metadata": {
    "language": "python",
    "name": "FEATURE_STORE_IMPLEMENTATION"
   },
   "outputs": [],
   "source": "# from snowflake.snowpark.functions import col\n# from snowflake.ml.feature_store import FeatureStore, CreationMode, FeatureView, Entity\n\n# # Set session context\n# session.use_database(\"DEV_DATA_SCIENCE_DB\")\n# session.use_schema(\"FEATURE_STORE_SCHEMA\")\n\n# # Initialize Feature Store\n# fs = FeatureStore(\n#     session=session,\n#     database=\"DEV_DATA_SCIENCE_DB\",\n#     name=\"FEATURE_STORE_SCHEMA\",\n#     default_warehouse=session.get_current_warehouse(),\n#     creation_mode=CreationMode.CREATE_IF_NOT_EXIST\n# )\n\n# # Register entity for CUSTOMERID, SNAPSHOT_DATE \n# # (required by Feature Store)\n# customer_entity = Entity(\n#     name=\"customer_entity\",\n#     join_keys=[\"CUSTOMERID\", \"SNAPSHOT_DATE\"],\n#     desc=\"Entity representing customer identifier\"\n# )\n\n# fs.register_entity(customer_entity)\n\n# # Use the object, not its name string\n# demographic_features = FeatureView(\n#     name=\"demographic_features\",\n#     entities=[customer_entity],\n#     feature_df=df.select(\n#         col(\"CUSTOMERID\"),\n#         col(\"SNAPSHOT_DATE\"),\n#         col(\"GENDER\"),\n#         col(\"SENIORCITIZEN\"),\n#         col(\"PARTNER\"),\n#         col(\"DEPENDENTS\")\n#     ),\n#     desc=\"Demographic-related features\"\n# )\n\n# fs.register_feature_view(demographic_features, version='1.0')\n\n# # Financial Features\n# financial_features = FeatureView(\n#     name=\"financial_features\",\n#     entities=[customer_entity],\n#     feature_df=df.select(\n#         col(\"CUSTOMERID\"),\n#         col(\"SNAPSHOT_DATE\"),\n#         col(\"MONTHLYCHARGES\"),\n#         col(\"TOTALCHARGES\"),\n#         col(\"PAYMENTMETHOD\"),\n#         col(\"PAPERLESSBILLING\")\n#     ),\n#     desc=\"Financial behavior and billing features\"\n# )\n# fs.register_feature_view(financial_features, version='1.0')\n\n# # Usage Features\n# usage_features = FeatureView(\n#     name=\"usage_features\",\n#     entities=[customer_entity],\n#     feature_df=df.select(\n#         col(\"CUSTOMERID\"),\n#         col(\"SNAPSHOT_DATE\"),\n#         col(\"PHONESERVICE\"),\n#         col(\"MULTIPLELINES\"),\n#         col(\"INTERNETSERVICE\"),\n#         col(\"ONLINESECURITY\"),\n#         col(\"ONLINEBACKUP\"),\n#         col(\"DEVICEPROTECTION\"),\n#         col(\"TECHSUPPORT\"),\n#         col(\"STREAMINGTV\"),\n#         col(\"STREAMINGMOVIES\"),\n#         col(\"CONTRACT\")\n#     ),\n#     desc=\"Usage and service interaction features\"\n# )\n# fs.register_feature_view(usage_features, version='1.0')\n\n# # Define Spine DataFrame\n# # Spine will include CUSTOMERID and the SNAPSHOT_DATE\n# spine_df = df.select(col(\"CUSTOMERID\"), col(\"SNAPSHOT_DATE\"))\n# # Get registered feature views\n# demographic_fv = fs.get_feature_view(name=\"demographic_features\", version=\"1.0\")\n# financial_fv = fs.get_feature_view(name=\"financial_features\", version=\"1.0\")\n# usage_fv = fs.get_feature_view(name=\"usage_features\", version=\"1.0\")\n\n# #---------------------------------------\n# # Deleting DataSet\n# from snowflake.ml.dataset import Dataset\n# # Load the existing Dataset\n# dataset = Dataset.load(session, name=\"churn_training_dataset\")\n# # Delete the specific version\n# dataset.delete_version(\"1.0\")\n# #---------------------------------------\n\n# # Generate training dataset\n# dataset = fs.generate_dataset(\n#     name=\"churn_training_dataset\",\n#     spine_df=spine_df,\n#     features=[demographic_fv, financial_fv, usage_fv],\n#     version=\"1.0\",\n#     desc=\"Churn training dataset with historical snapshots\"\n# )\n\n# # Convert Snowpark DataFrame to Pandas for ML\n# df = dataset.read.to_snowpark_dataframe()\n# df = df.join(label_df, on=[\"CUSTOMERID\", \"SNAPSHOT_DATE\"], how=\"inner\")\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "51941e56-a273-41a6-8065-6f183aa7535a",
   "metadata": {
    "language": "python",
    "name": "cell3"
   },
   "outputs": [],
   "source": "from snowflake.snowpark.functions import col, when\nfrom snowflake.ml.modeling.ensemble import RandomForestClassifier\nfrom snowflake.ml.modeling.metrics import accuracy_score\n\n# -----------------------------\n# Apply preprocessing to Snowpark DataFrame\ndf = preprocess_after_feature_store(df)\ndf.show()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1d7a1074-8a7f-461f-bd0e-74c8793550ad",
   "metadata": {
    "language": "python",
    "name": "cell4"
   },
   "outputs": [],
   "source": "# Write Post Processed Data to Snowflake table\ndf.write.mode(\"append\").save_as_table(\"POST_PROCESSED_FEATURES_DATA\")",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "0fc042d8-3216-491c-a989-e671dca73b51",
   "metadata": {
    "language": "python",
    "name": "cell1"
   },
   "outputs": [],
   "source": "# -----------------------------\n# Exclude non-numeric or irrelevant columns\nexcluded_cols = {\"CUSTOMERID\", \"CHURN\", \"SNAPSHOT_DATE\"}\n\n# Select only numeric/one-hot columns for model training\nfeature_cols = [col_name for col_name in df.columns if col_name not in excluded_cols]\n\n# -----------------------------\n# Split the data into training and testing sets\ntrain_df, test_df = df.randomSplit([0.8, 0.2], seed=42)\n\n# -----------------------------\n# Initialize and train the model\nrf_model = RandomForestClassifier(\n    input_cols=feature_cols,\n    label_cols=[\"CHURN\"],\n    output_cols=[\"PREDICTION\"],\n    n_estimators=100,\n    random_state=42\n)\n\nrf_model.fit(train_df)\n\n# -----------------------------\n# Make predictions\npredictions = rf_model.predict(test_df)\n\n# -----------------------------\n# Evaluate accuracy\naccuracy = accuracy_score(\n    df=predictions,\n    y_true_col_names=[\"CHURN\"],\n    y_pred_col_names=[\"PREDICTION\"]\n)\n\nprint(f\"Model Accuracy: {accuracy:.4f}\")\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e28c9c9c-7bcd-45ba-b46c-f6a0e6414cb7",
   "metadata": {
    "language": "python",
    "name": "cell2"
   },
   "outputs": [],
   "source": "# Initialize Model Registry\nregistry = Registry(\n    session=session,\n    database_name=\"DEV_DATA_SCIENCE_DB\",       # Replace with your database name\n    schema_name=\"MODEL_REGISTRY_SCHEMA\"    # Replace with your schema name\n)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b0dffb4e-0174-4fa4-9451-cb5d034c6de8",
   "metadata": {
    "language": "python",
    "name": "cell6"
   },
   "outputs": [],
   "source": "sample_input_data = train_df.select(feature_cols).limit(10)\nmodel_name = \"CHURN_PRED_MODEL\"\nmodel_version = registry.log_model(\n    model=rf_model,\n    model_name=\"CHURN_PRED_MODEL\",\n    version_name=\"v4\",\n    comment=\"Random Forest model for churn prediction\",\n    sample_input_data=sample_input_data,\n)\n\nmodel_version = registry.get_model(\"CHURN_PRED_MODEL\").version(\"v4\")\npredictions = model_version.run(test_df, function_name=\"predict\")\npredictions.show()\nfrom snowflake.ml.modeling.metrics import accuracy_score\n\naccuracy = accuracy_score(\n    df=predictions,\n    y_true_col_names=[\"CHURN\"],\n    y_pred_col_names=[\"PREDICTION\"]\n)\nprint(f\"Model Accuracy: {accuracy:.4f}\")",
   "execution_count": null
  }
 ]
}