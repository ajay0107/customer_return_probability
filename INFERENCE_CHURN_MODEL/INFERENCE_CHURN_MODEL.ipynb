{
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  },
  "lastEditStatus": {
   "notebookId": "jqr52rivdzzidek4wt6x",
   "authorId": "2665515635921",
   "authorName": "AJAY01071992",
   "authorEmail": "ajay01071992@gmail.com",
   "sessionId": "e48a2991-dafc-42fc-b151-fe34614c809c",
   "lastEditTime": 1749138182831
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "id": "c1d1dfba-dbe6-4584-a72f-1357b32d7374",
   "metadata": {
    "language": "python",
    "name": "PACKAGES_IMPORT"
   },
   "outputs": [],
   "source": "import pandas as pd\nimport numpy as np\nimport shap\nfrom snowflake.snowpark.functions import col, when\nfrom snowflake.ml.modeling.ensemble import RandomForestClassifier\nfrom snowflake.ml.modeling.metrics import accuracy_score\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import train_test_split\nfrom snowflake.snowpark.context import get_active_session\nfrom snowflake.snowpark.types import FloatType, DateType\nfrom snowflake.snowpark import Session\nfrom snowflake.snowpark.functions import col, when, regexp_replace\nfrom datetime import datetime\nfrom snowflake.snowpark.functions import lit, current_date, current_timestamp\nfrom snowflake.snowpark.types import IntegerType\nfrom snowflake.ml.feature_store import (\n    FeatureStore,\n    FeatureView,\n    Entity,\n    CreationMode\n)\nfrom sklearn.metrics import (\n    accuracy_score,\n    precision_score,\n    recall_score,\n    f1_score,\n    roc_auc_score,\n    average_precision_score\n)\nfrom snowflake.ml.modeling.pipeline import Pipeline\nfrom snowflake.ml.modeling.xgboost import XGBClassifier\nfrom snowflake.ml.registry import Registry\nfrom snowflake.ml.model import model_signature\n# from snowflake.ml.modeling.model_selection import train_test_split\nfrom datetime import date",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3ab7decf-2236-4807-8b28-3162a23eddbf",
   "metadata": {
    "language": "python",
    "name": "HELPER_FUNCTIONS"
   },
   "outputs": [],
   "source": "def preprocess_after_feature_store(df):\n    # Convert target to binary label\n    df = df.with_column(\"CHURN\", when(col(\"CHURN\") == \"Yes\", 1).otherwise(0))\n\n    # Categorical columns to one-hot encode\n    onehot_columns = [\n        \"GENDER\", \"PARTNER\", \"DEPENDENTS\", \"PHONESERVICE\", \"MULTIPLELINES\", \"INTERNETSERVICE\",\n        \"ONLINESECURITY\", \"ONLINEBACKUP\", \"DEVICEPROTECTION\", \"TECHSUPPORT\",\n        \"STREAMINGTV\", \"STREAMINGMOVIES\", \"CONTRACT\", \"PAPERLESSBILLING\", \"PAYMENTMETHOD\"\n    ]\n\n    # One-hot encoding manually\n    for column_name in onehot_columns:\n        unique_vals = df.select(col(column_name)).distinct().collect()\n        for row in unique_vals:\n            value = row[column_name]\n            if value is not None:\n                safe_value = str(value).replace(' ', '_').replace('-', '_').replace('(', '').replace(')', '')\n                new_col = f\"{column_name}_{safe_value}\"\n                df = df.with_column(new_col, when(col(column_name) == value, 1).otherwise(0))\n\n    # Drop original categorical columns\n    df = df.drop(*onehot_columns)\n    return df\n\ndef clean_total_charges_column(df):\n    \"\"\"\n    Cleans the TOTALCHARGES column:\n    - Replaces known invalid values ('', 'No', 'N/A', etc.) with NULL\n    - Removes non-numeric characters from valid entries\n    - Casts to FloatType\n    \"\"\"\n    df = df.with_column(\n        \"TOTALCHARGES_CLEANED\",\n        when(\n            (col(\"TOTALCHARGES\").is_null()) |\n            (col(\"TOTALCHARGES\") == '') |\n            (col(\"TOTALCHARGES\").isin(\"No\", \"N/A\", \"null\", \"None\")),\n            None\n        ).otherwise(\n            regexp_replace(col(\"TOTALCHARGES\"), r\"[^0-9.]\", \"\")\n        ).cast(FloatType())\n    )\n    # Optionally drop original and rename\n    df = df.drop(\"TOTALCHARGES\").with_column_renamed(\"TOTALCHARGES_CLEANED\", \"TOTALCHARGES\")\n    return df",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c695373e-ac74-4b62-a1f1-08206cbd5c81",
   "metadata": {
    "language": "python",
    "name": "SETUP_ENVIRONMENT"
   },
   "source": "session = get_active_session()\n\n# Add a query tag to the session. This helps with debugging and performance monitoring.\nsession.query_tag = session.query_tag = {\n    \"origin\": \"churn_data_science\",\n    \"name\": \"churn_prediction_model_training\",\n    \"version\": {\"major\": 1, \"minor\": 0},\n    \"attributes\": {\"training\": 1, \"source\": \"notebook\"}\n}\n\n# Set session context \nsession.use_role(\"DEV_DATA_SCIENCE\") \n# Set the compute warehouse (used to run queries and transformations)\nsession.use_warehouse(\"DEV_DATA_SCIENCE_WH\")\n\n# Set the active database (logical container for schemas and tables)\nsession.use_database(\"DEV_DATA_SCIENCE_DB\")\n\n# Set the active schema (namespace within the database)\nsession.use_schema(\"CHURN_MODEL_SCHEMA\")\n\n# Print the current role, warehouse, and database/schema\nprint(f\"Session role: {session.get_current_role()} \\nSession WH: {session.get_current_warehouse()} \\nSession DB.SCHEMA: {session.get_fully_qualified_current_schema()}\")\n\n# Feature Store schema reference\nFEATURE_STORE_SCHEMA = \"DEV_DATA_SCIENCE_DB.FEATURE_STORE_SCHEMA\"\n\n# Model Registry schema reference\nMODEL_REGISTRY_SCHEMA = \"DEV_DATA_SCIENCE_DB.MODEL_REGISTRY_SCHEMA\"\n\n# Print the current role, warehouse, and database/schema\nprint(f\"FEATURE_STORE_SCHEMA: {FEATURE_STORE_SCHEMA} \\nMODEL_REGISTRY_SCHEMA: {MODEL_REGISTRY_SCHEMA}\")\n",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "51941e56-a273-41a6-8065-6f183aa7535a",
   "metadata": {
    "language": "python",
    "name": "FEATURES_LOADING"
   },
   "outputs": [],
   "source": "# Read the SQL query string\nsql_file_path = \"TRAIN_CHURN_MODEL_V2/features_ingest.sql\"\nwith open(sql_file_path, \"r\") as file:\n    sql_query = file.read()\n\n# Execute the SQL query using Snowpark\ndf = session.sql(sql_query)\n\n# Apply preprocessing to Snowpark DataFrame\ndf = preprocess_after_feature_store(df)\ndf.show()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "0fc042d8-3216-491c-a989-e671dca73b51",
   "metadata": {
    "language": "python",
    "name": "MODEL_TRAINING"
   },
   "outputs": [],
   "source": "# -----------------------------\n# Exclude non-numeric or irrelevant columns\nexcluded_cols = {\"CUSTOMERID\", \"CHURN\", \"SNAPSHOT_DATE\"}\n\n# Select only numeric/one-hot columns for model training\nfeature_cols = [\n    col_name for col_name in df.columns \n    if col_name.upper() not in excluded_cols\n]\n\n# -----------------------------\n# Split the data into training and testing sets\ntrain_df, test_df = df.randomSplit([0.8, 0.2], seed=42)\n\n# -----------------------------\n# Initialize and train the model\nrf_model = RandomForestClassifier(\n    input_cols=feature_cols,\n    label_cols=[\"CHURN\"],\n    output_cols=[\"PREDICTION\"],\n    n_estimators=100,\n    random_state=42\n)\n\nrf_model.fit(train_df)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e28c9c9c-7bcd-45ba-b46c-f6a0e6414cb7",
   "metadata": {
    "language": "python",
    "name": "MODEL_VALIDATION_AND_REGISTRY"
   },
   "outputs": [],
   "source": "today_str = date.today().strftime(\"%Y_%m_%d\")\n\n# Initialize Model Registry\nregistry = Registry(\n    session=session,\n    database_name=\"DEV_DATA_SCIENCE_DB\", \n    schema_name=\"MODEL_REGISTRY_SCHEMA\"\n)\n\n# -----------------------------\n# Sample input for registry\nsample_input_data = train_df.select(feature_cols).limit(10)\n\n# -----------------------------\n# Define model name and version\nversion_str = f\"V_{today_str}\"\nmodel_name = f\"CHURN_RF_V1_{version_str}\"\ndev_comment = \"Random Forest model for churn prediction\"\n# -----------------------------\n# Log model to registry\nmodel_version = registry.log_model(\n    model=rf_model,\n    model_name=model_name,\n    version_name=version_str,\n    comment=dev_comment,\n    sample_input_data=sample_input_data,\n)\n\n# -----------------------------\n# Fetch versioned model from registry\nmodel_version = registry.get_model(model_name).version(version_str)\n\n# -----------------------------\n# Get predicted probabilities\nproba_df = model_version.run(test_df, function_name=\"predict_proba\")\n\n\n# -----------------------------\n# Apply threshold manually\nthreshold = 0.5  # you can change this\n# Assumes output column is a 2-element array: [prob_class_0, prob_class_1]\nproba_df = proba_df.with_column(\n    \"PREDICTION\",\n    when(col('\"PREDICT_PROBA_1\"') >= threshold, 1).otherwise(0)\n)\n# -----------------------------\n# Evaluate metrics\ntrue_vals = test_df.select(\"CHURN\").to_pandas()[\"CHURN\"].astype(int).values\npred_vals = proba_df.select(\"PREDICTION\").to_pandas()[\"PREDICTION\"].astype(int).values\nprob_vals = proba_df.select('\"PREDICT_PROBA_1\"').to_pandas()[\"PREDICT_PROBA_1\"].values\n\nacc = accuracy_score(true_vals, pred_vals)\nprec = precision_score(true_vals, pred_vals, zero_division=0)\nrec = recall_score(true_vals, pred_vals, zero_division=0)\nf1 = f1_score(true_vals, pred_vals, zero_division=0)\nroc_auc = roc_auc_score(true_vals, prob_vals)\npr_auc = average_precision_score(true_vals, prob_vals)\n\nprint(f\"Accuracy: {acc:.4f}\")\nprint(f\"Precision: {prec:.4f}\")\nprint(f\"Recall: {rec:.4f}\")\nprint(f\"F1 Score: {f1:.4f}\")\nprint(f\"ROC AUC: {roc_auc:.4f}\")\nprint(f\"PR AUC: {pr_auc:.4f}\")\n\n# -----------------------------\n# Log metrics to model registry\nmodel_version.set_metric(\"accuracy\", acc)\nmodel_version.set_metric(\"precision\", prec)\nmodel_version.set_metric(\"recall\", rec)\nmodel_version.set_metric(\"f1_score\", f1)\nmodel_version.set_metric(\"roc_auc\", roc_auc)\nmodel_version.set_metric(\"pr_auc\", pr_auc)\n\nprint(\"Metrics logged to model registry.\")\n\n\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "81f6b3db-51b5-4af0-8812-4bb01e2bef77",
   "metadata": {
    "language": "python",
    "name": "MODEL_PERFORMANCE_STORE"
   },
   "outputs": [],
   "source": "# Define model metrics and metadata\ntraining_date = datetime.today().date()\n\n# Example metric values\nprecision = 0.81\nrecall = 0.76\nf1_score = 0.78\naccuracy = 0.84\nroc_auc = 0.89\npr_auc = 0.75\nthreshold = 0.5\n\n# Create a DataFrame to insert the values\nmetrics_df = session.create_dataframe([[\n    model_name,\n    training_date,\n    prec,\n    rec,\n    f1,\n    acc,\n    roc_auc,\n    pr_auc,\n    threshold,\n    dev_comment\n]], schema=[\n    \"MODEL_ID\",\n    \"TRAINING_DATE\",\n    \"PRECISION\",\n    \"RECALL\",\n    \"F1_SCORE\",\n    \"ACCURACY\",\n    \"ROC_AUC\",\n    \"PR_AUC\",\n    \"THRESHOLD\",\n    \"COMMENT\"\n])\n\n# Insert into the target table\nmetrics_df.write.mode(\"append\").save_as_table(\"DEV_DATA_SCIENCE_DB.CHURN_MODEL_SCHEMA.MODEL_PERFORMANCE_METRICS\")",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "afa3baf1-8622-4375-9cfb-31b496a01bd3",
   "metadata": {
    "language": "python",
    "name": "FEATURE_IMPORTANCE_STORE",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "# Get feature importances and feature names\nrf_model_sk = rf_model.to_sklearn()\nimportances = rf_model_sk.feature_importances_\nfeature_names = feature_cols  # or manually provided list\n\n# Pair and sort\nsorted_importances = sorted(\n    zip(feature_names, importances),\n    key=lambda x: x[1],\n    reverse=True\n)\n\n# Create rows with rank (CREATED_AT is auto-handled by Snowflake)\nfeature_data = [\n    (model_name, fname, round(score, 5), rank + 1, training_date)\n    for rank, (fname, score) in enumerate(sorted_importances)\n]\n\n# Create Snowpark DataFrame\nimportance_df = session.create_dataframe(\n    feature_data,\n    schema=[\"MODEL_ID\", \"FEATURE_NAME\", \"IMPORTANCE_SCORE\", \"RANK\", \"TRAINING_DATE\"]\n)\n\n# Write to Snowflake table\nimportance_df.write.mode(\"append\").save_as_table(\"DEV_DATA_SCIENCE_DB.CHURN_MODEL_SCHEMA.FEATURE_IMPORTANCE\")",
   "execution_count": null
  }
 ]
}