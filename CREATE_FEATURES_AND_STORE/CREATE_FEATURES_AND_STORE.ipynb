{
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  },
  "lastEditStatus": {
   "notebookId": "jqr52rivdzzidek4wt6x",
   "authorId": "2665515635921",
   "authorName": "AJAY01071992",
   "authorEmail": "ajay01071992@gmail.com",
   "sessionId": "6dc7b493-05a1-44c6-902d-25b02616f1a7",
   "lastEditTime": 1749119625885
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "id": "c1d1dfba-dbe6-4584-a72f-1357b32d7374",
   "metadata": {
    "language": "python",
    "name": "PACKAGES_IMPORT"
   },
   "outputs": [],
   "source": "import pandas as pd\n\nfrom snowflake.snowpark.functions import col, when\nfrom snowflake.ml.modeling.ensemble import RandomForestClassifier\nfrom snowflake.ml.modeling.metrics import accuracy_score\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import train_test_split\nfrom snowflake.snowpark.context import get_active_session\nfrom snowflake.snowpark.types import FloatType, DateType\nfrom snowflake.snowpark import Session\nfrom snowflake.snowpark.functions import col, when, regexp_replace\nfrom datetime import datetime\nfrom snowflake.snowpark.functions import lit, current_date, current_timestamp\nfrom snowflake.snowpark.types import IntegerType\nfrom snowflake.ml.feature_store import (\n    FeatureStore,\n    FeatureView,\n    Entity,\n    CreationMode\n)\nfrom snowflake.ml.modeling.pipeline import Pipeline\nfrom snowflake.ml.modeling.xgboost import XGBClassifier\nfrom snowflake.ml.registry import Registry\nfrom snowflake.ml.model import model_signature\n# from snowflake.ml.modeling.model_selection import train_test_split",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9a22c5ca-ed47-4afe-be95-1342e919b086",
   "metadata": {
    "language": "python",
    "name": "HELPER_FUNCTIONS"
   },
   "outputs": [],
   "source": "def clean_column_names(df):\n    cleaned_cols = {col_name: col_name.strip().replace('\"', '') for col_name in df.columns}\n    return df.select([col(c).alias(cleaned_cols[c]) for c in df.columns])\n\ndef preprocess_before_feature_store(df):\n    # Clean column names\n    df = df.select([col(c).alias(c.strip().replace('\"', '')) for c in df.columns])\n\n    # Cast numeric fields properly\n    df = df.with_column(\"SeniorCitizen\", col(\"SeniorCitizen\").cast(IntegerType()))\n    df = df.with_column(\"tenure\", col(\"tenure\").cast(IntegerType()))\n    df = df.with_column(\"MonthlyCharges\", col(\"MonthlyCharges\").cast(\"float\"))\n    df = df.with_column(\n        \"TotalCharges\",\n        when(col(\"TotalCharges\") == ' ', None).otherwise(col(\"TotalCharges\")).cast(\"float\")\n    )\n\n    # Drop rows with nulls in critical numeric fields\n    df = df.filter(col(\"TotalCharges\").is_not_null())\n\n    return df\n\ndef preprocess_after_feature_store(df):\n    # Convert target to binary label\n    df = df.with_column(\"CHURN\", when(col(\"CHURN\") == \"Yes\", 1).otherwise(0))\n\n    # Categorical columns to one-hot encode\n    onehot_columns = [\n        \"GENDER\", \"PARTNER\", \"DEPENDENTS\", \"PHONESERVICE\", \"MULTIPLELINES\", \"INTERNETSERVICE\",\n        \"ONLINESECURITY\", \"ONLINEBACKUP\", \"DEVICEPROTECTION\", \"TECHSUPPORT\",\n        \"STREAMINGTV\", \"STREAMINGMOVIES\", \"CONTRACT\", \"PAPERLESSBILLING\", \"PAYMENTMETHOD\"\n    ]\n\n    # One-hot encoding manually\n    for column_name in onehot_columns:\n        unique_vals = df.select(col(column_name)).distinct().collect()\n        for row in unique_vals:\n            value = row[column_name]\n            if value is not None:\n                safe_value = str(value).replace(' ', '_').replace('-', '_').replace('(', '').replace(')', '')\n                new_col = f\"{column_name}_{safe_value}\"\n                df = df.with_column(new_col, when(col(column_name) == value, 1).otherwise(0))\n\n    # Drop original categorical columns\n    df = df.drop(*onehot_columns)\n    return df\n\ndef clean_total_charges_column(df):\n    \"\"\"\n    Cleans the TOTALCHARGES column:\n    - Replaces known invalid values ('', 'No', 'N/A', etc.) with NULL\n    - Removes non-numeric characters from valid entries\n    - Casts to FloatType\n    \"\"\"\n    df = df.with_column(\n        \"TOTALCHARGES_CLEANED\",\n        when(\n            (col(\"TOTALCHARGES\").is_null()) |\n            (col(\"TOTALCHARGES\") == '') |\n            (col(\"TOTALCHARGES\").isin(\"No\", \"N/A\", \"null\", \"None\")),\n            None\n        ).otherwise(\n            regexp_replace(col(\"TOTALCHARGES\"), r\"[^0-9.]\", \"\")\n        ).cast(FloatType())\n    )\n    # Optionally drop original and rename\n    df = df.drop(\"TOTALCHARGES\").with_column_renamed(\"TOTALCHARGES_CLEANED\", \"TOTALCHARGES\")\n    return df",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c695373e-ac74-4b62-a1f1-08206cbd5c81",
   "metadata": {
    "language": "python",
    "name": "SETUP_ENVIRONMENT"
   },
   "source": "session = get_active_session()\n\n# Add a query tag to the session. This helps with debugging and performance monitoring.\nsession.query_tag = session.query_tag = {\n    \"origin\": \"churn_data_science\",\n    \"name\": \"churn_prediction_model_training\",\n    \"version\": {\"major\": 1, \"minor\": 0},\n    \"attributes\": {\"training\": 1, \"source\": \"notebook\"}\n}\n\n# Set session context \nsession.use_role(\"DEV_DATA_SCIENCE\") \n# Set the compute warehouse (used to run queries and transformations)\nsession.use_warehouse(\"DEV_DATA_SCIENCE_WH\")\n\n# Set the active database (logical container for schemas and tables)\nsession.use_database(\"DEV_DATA_SCIENCE_DB\")\n\n# Set the active schema (namespace within the database)\nsession.use_schema(\"CHURN_MODEL_SCHEMA\")\n\n# Print the current role, warehouse, and database/schema\nprint(f\"Session role: {session.get_current_role()} \\nSession WH: {session.get_current_warehouse()} \\nSession DB.SCHEMA: {session.get_fully_qualified_current_schema()}\")\n\n# Feature Store schema reference\nFEATURE_STORE_SCHEMA = \"DEV_DATA_SCIENCE_DB.FEATURE_STORE_SCHEMA\"\n\n# Model Registry schema reference\nMODEL_REGISTRY_SCHEMA = \"DEV_DATA_SCIENCE_DB.MODEL_REGISTRY_SCHEMA\"\n\n# Print the current role, warehouse, and database/schema\nprint(f\"FEATURE_STORE_SCHEMA: {FEATURE_STORE_SCHEMA} \\nMODEL_REGISTRY_SCHEMA: {MODEL_REGISTRY_SCHEMA}\")\n",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "86532cdd-f92b-41d9-9b91-1c25aa291b24",
   "metadata": {
    "language": "python",
    "name": "DATA_LOADING_AND_SAVE_IN_RAW_FEATURES_DATA"
   },
   "outputs": [],
   "source": "# Read the SQL query string\nsql_file_path = \"TRAIN_CHURN_MODEL_V2/features_ingest.sql\"\nwith open(sql_file_path, \"r\") as file:\n    sql_query = file.read()\n\n# Execute the SQL query using Snowpark\ndf = session.sql(sql_query)\n\n# Clean column names: remove quotes and standardize to uppercase\ncleaned_columns = {col_name: col_name.strip('\"').upper() for col_name in df.columns}\ndf = df.select([col(c).alias(cleaned_columns[c]) for c in df.columns])\n\n# Add SNAPSHOT_DATE column with current date\ndf = df.with_column(\"SNAPSHOT_DATE\", current_date())\n\n# Write to Snowflake table\ndf.write.mode(\"append\").save_as_table(\"DEV_DATA_SCIENCE_DB.FEATURE_STORE_SCHEMA.CUSTOMERID_LVL_RAW_DATA\")",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ed9613f5-ac01-4f09-a61a-2b5cf2509e1a",
   "metadata": {
    "language": "python",
    "name": "DATA_PREPROCESSING"
   },
   "outputs": [],
   "source": "df = clean_column_names(df)\ndf = preprocess_before_feature_store(df)\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8f418df3-755a-4c9a-828c-4c18e9b5332b",
   "metadata": {
    "language": "python",
    "name": "STORE_FEATURES"
   },
   "outputs": [],
   "source": "# Write to Snowflake Feature Store\ndf.write.mode(\"append\").save_as_table(\"DEV_DATA_SCIENCE_DB.FEATURE_STORE_SCHEMA.CUSTOMERID_LVL_FEATURES_DATA\")",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "51941e56-a273-41a6-8065-6f183aa7535a",
   "metadata": {
    "language": "python",
    "name": "cell3"
   },
   "outputs": [],
   "source": "# Apply preprocessing to Snowpark DataFrame\ndf = preprocess_after_feature_store(df)\ndf.show()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "0fc042d8-3216-491c-a989-e671dca73b51",
   "metadata": {
    "language": "python",
    "name": "cell1"
   },
   "outputs": [],
   "source": "# -----------------------------\n# Exclude non-numeric or irrelevant columns\nexcluded_cols = {\"CUSTOMERID\", \"CHURN\", \"SNAPSHOT_DATE\"}\n\n# Select only numeric/one-hot columns for model training\nfeature_cols = [col_name for col_name in df.columns if col_name not in excluded_cols]\n\n# -----------------------------\n# Split the data into training and testing sets\ntrain_df, test_df = df.randomSplit([0.8, 0.2], seed=42)\n\n# -----------------------------\n# Initialize and train the model\nrf_model = RandomForestClassifier(\n    input_cols=feature_cols,\n    label_cols=[\"CHURN\"],\n    output_cols=[\"PREDICTION\"],\n    n_estimators=100,\n    random_state=42\n)\n\nrf_model.fit(train_df)\n\n# -----------------------------\n# Make predictions\npredictions = rf_model.predict(test_df)\n\n# -----------------------------\n# Evaluate accuracy\naccuracy = accuracy_score(\n    df=predictions,\n    y_true_col_names=[\"CHURN\"],\n    y_pred_col_names=[\"PREDICTION\"]\n)\n\nprint(f\"Model Accuracy: {accuracy:.4f}\")\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e28c9c9c-7bcd-45ba-b46c-f6a0e6414cb7",
   "metadata": {
    "language": "python",
    "name": "cell2"
   },
   "outputs": [],
   "source": "# Initialize Model Registry\nregistry = Registry(\n    session=session,\n    database_name=\"DEV_DATA_SCIENCE_DB\",       # Replace with your database name\n    schema_name=\"MODEL_REGISTRY_SCHEMA\"    # Replace with your schema name\n)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b0dffb4e-0174-4fa4-9451-cb5d034c6de8",
   "metadata": {
    "language": "python",
    "name": "cell6"
   },
   "outputs": [],
   "source": "sample_input_data = train_df.select(feature_cols).limit(10)\nmodel_name = \"CHURN_PRED_MODEL\"\nmodel_version = registry.log_model(\n    model=rf_model,\n    model_name=\"CHURN_PRED_MODEL\",\n    version_name=\"v4\",\n    comment=\"Random Forest model for churn prediction\",\n    sample_input_data=sample_input_data,\n)\n\nmodel_version = registry.get_model(\"CHURN_PRED_MODEL\").version(\"v4\")\npredictions = model_version.run(test_df, function_name=\"predict\")\npredictions.show()\nfrom snowflake.ml.modeling.metrics import accuracy_score\n\naccuracy = accuracy_score(\n    df=predictions,\n    y_true_col_names=[\"CHURN\"],\n    y_pred_col_names=[\"PREDICTION\"]\n)\nprint(f\"Model Accuracy: {accuracy:.4f}\")",
   "execution_count": null
  }
 ]
}